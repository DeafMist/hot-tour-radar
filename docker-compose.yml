services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_log:/var/lib/zookeeper/log

  kafka:
    image: confluentinc/cp-kafka:7.5.3
    container_name: kafka
    hostname: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,INTERNAL://kafka:9093
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,INTERNAL://0.0.0.0:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9093", "--list"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    volumes:
      - kafka_data:/var/lib/kafka/data

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - "8081:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9093
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    restart: unless-stopped

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.4
    environment:
      - discovery.type=single-node
      # For development/testing purposes only
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
    ports:
      - "9200:9200"
    volumes:
      - es_data:/usr/share/elasticsearch/data

  worker:
    build:
      context: .
      dockerfile: backend/Dockerfile
      args:
        SERVICE: worker
    depends_on:
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_started
    environment:
      KAFKA_BROKERS: kafka:9093
      KAFKA_TOPIC: news_raw
      KAFKA_CONSUMER_GROUP: news-worker
      ELASTICSEARCH_ADDR: http://elasticsearch:9200
      ELASTICSEARCH_INDEX: news
      LOG_LEVEL: info

  news-scraper:
    build:
      context: ./scraper
      dockerfile: Dockerfile
    env_file:
      - .env
    container_name: news-scraper
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BROKERS: kafka:9093
      KAFKA_TOPIC: news_raw
      TELEGRAM_API_ID: ${TELEGRAM_API_ID}
      TELEGRAM_API_HASH: ${TELEGRAM_API_HASH}
      TELEGRAM_CHANNELS: ${TELEGRAM_CHANNELS}
    volumes:
      - ./scraper/src/news_parser_session.session:/app/news_parser_session.session
    restart: unless-stopped

  api:
    build:
      context: .
      dockerfile: backend/Dockerfile
      args:
        SERVICE: api
    depends_on:
      - elasticsearch
    ports:
      - "8080:8080"
    environment:
      API_BIND_ADDR: ":8080"
      ELASTICSEARCH_ADDR: http://elasticsearch:9200
      ELASTICSEARCH_INDEX: news
      LOG_LEVEL: info

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: search-frontend
    ports:
      - "3000:80"
    depends_on:
      - api
    restart: unless-stopped

  retention:
    build:
      context: .
      dockerfile: backend/Dockerfile
      args:
        SERVICE: retention
    depends_on:
      - elasticsearch
    environment:
      ELASTICSEARCH_ADDR: http://elasticsearch:9200
      ELASTICSEARCH_INDEX: news
      RETENTION_CRON: 24h
      RETENTION_MAX_AGE: 168h
      LOG_LEVEL: info

volumes:
  kafka_data:
  zookeeper_data:
  zookeeper_log:
  es_data:
